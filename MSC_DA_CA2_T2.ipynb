{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217e0670",
   "metadata": {},
   "source": [
    "# Download libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268f0605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytz in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (2022.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweepy in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (4.12.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.27.0->tweepy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (0.13.5)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels) (1.7.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.25->statsmodels) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (5.6.0)\n",
      "Requirement already satisfied: six in c:\\users\\onceu\\appdata\\roaming\\python\\python39\\site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytz\n",
    "!pip install tweepy\n",
    "!pip install statsmodels\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8bf5c8",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ec967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "from pytz import timezone\n",
    "import tweepy\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.errors import EmptyDataError\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85e1ba",
   "metadata": {},
   "source": [
    "# Loading the credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65039743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter API connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Load the Twitter API credentials from the config file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    consumer_key = config['consumer_key']\n",
    "    consumer_secret = config['consumer_secret']\n",
    "    access_token = config['access_token']\n",
    "    access_token_secret = config['access_token_secret']\n",
    "    \n",
    "# Verify the Twitter API credentials\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "try:\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    user = api.verify_credentials()\n",
    "    print(\"Twitter API connection successful.\")\n",
    "except tweepy.error.TweepError as e:\n",
    "    print(\"Error: Failed to verify Twitter API credentials.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d1610",
   "metadata": {},
   "source": [
    "# Disabling warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374410ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c567c",
   "metadata": {},
   "source": [
    "# Downloading and save twitter data\n",
    "The free tier of the twitter API holds the limitation of:</br>\n",
    "<b>**7 Day tweet history limit </br>\n",
    "**1500 tweet request limit </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a17cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "today = datetime.now().date()\n",
    "\n",
    "# Create a log file name with today's date\n",
    "log_file = f\"TwitterAPI_{today}.log\"\n",
    "\n",
    "# Check if the log file exists\n",
    "if os.path.isfile(log_file):\n",
    "    # Append logs to the existing file\n",
    "    sys.stdout = open(log_file, \"a\")\n",
    "else:\n",
    "    # Create a new log file\n",
    "    sys.stdout = open(log_file, \"w\")\n",
    "\n",
    "# Define the topic and initial date range\n",
    "topic = \"(ios OR apple OR AAPL OR iphone OR ipad)\"\n",
    "start_date = today - timedelta(days=91)\n",
    "\n",
    "# Create a loop to run for 91 days\n",
    "for _ in range(91):\n",
    "    # Calculate the end date for the current iteration\n",
    "    end_date = start_date + timedelta(days=1)\n",
    "    \n",
    "    # Format the dates as strings\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Define the search query with the current date range\n",
    "    query = f\"{topic} until:{end_date_str} since:{start_date_str}\"\n",
    "    \n",
    "    # Fetch tweets on the specified topic\n",
    "    try:\n",
    "        tweets = []\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=query, lang='en', tweet_mode='extended').items(1500):\n",
    "            tweets.append({\n",
    "                'Date': tweet.created_at.date(),\n",
    "                'Tweet': tweet.full_text\n",
    "            })\n",
    "        \n",
    "        if len(tweets) > 0:\n",
    "            print(\"Tweets downloaded successfully for the date range:\", start_date_str, \"to\", end_date_str)\n",
    "            \n",
    "            # Convert the tweets list into a DataFrame\n",
    "            df_new = pd.DataFrame(tweets)\n",
    "            \n",
    "            # Check if the CSV file already exists\n",
    "            if os.path.isfile('tweets.csv'):\n",
    "                # Read the existing data from the CSV file\n",
    "                try:\n",
    "                    df_existing = pd.read_csv('tweets.csv')\n",
    "                    \n",
    "                    # Check if the existing DataFrame has any columns\n",
    "                    if df_existing.columns.empty:\n",
    "                        # Handle the case when the CSV file is empty\n",
    "                        df_existing = pd.DataFrame()\n",
    "                        \n",
    "                except pd.errors.EmptyDataError:\n",
    "                    # Handle the case when the CSV file is empty\n",
    "                    df_existing = pd.DataFrame()\n",
    "                \n",
    "                # Check if the existing DataFrame is empty\n",
    "                if df_existing.empty:\n",
    "                    # Save the new DataFrame to a new CSV file\n",
    "                    df_new.to_csv('tweets.csv', index=False)\n",
    "                    print(\"New CSV file created with the downloaded tweets.\")\n",
    "                else:\n",
    "                    # Concatenate the existing and new data\n",
    "                    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "                    \n",
    "                    # Save the combined DataFrame to the CSV file\n",
    "                    df_combined.to_csv('tweets.csv', index=False)\n",
    "                    print(\"Tweets appended to the existing CSV file.\")\n",
    "            else:\n",
    "                # Save the new DataFrame to a new CSV file\n",
    "                df_new.to_csv('tweets.csv', index=False)\n",
    "                print(\"New CSV file created with the downloaded tweets.\")\n",
    "        else:\n",
    "            print(\"No tweets found for the date range:\", start_date_str, \"to\", end_date_str)\n",
    "            \n",
    "    except tweepy.TweepyException as e:\n",
    "        if e.api_code == 88:\n",
    "            # Rate limit reached, wait for the specified duration\n",
    "            wait_time = int(e.response.headers['Retry-After'])\n",
    "            print(\"Rate limit reached. Sleeping for:\", wait_time, \"seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "        print(\"Error: Failed to download tweets.\")\n",
    "        print(e)\n",
    "    \n",
    "    # Update the start date for the next iteration\n",
    "    start_date = end_date\n",
    "\n",
    "# Close the log file\n",
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262887ea",
   "metadata": {},
   "source": [
    "# Log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bca447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the log file into a DataFrame\n",
    "log_df = pd.read_csv(\"log_file\", sep=\":\", names=[\"Timestamp\", \"Log Message\"])\n",
    "# Display the log DataFrame\n",
    "log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b9608",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tweets from the CSV file\n",
    "df = pd.read_csv('tweets.csv')\n",
    "\n",
    "# Perform sentiment analysis using TextBlob\n",
    "df['sentiment'] = df['Tweet'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Classify sentiment as positive, negative, or neutral\n",
    "df['sentiment_label'] = df['sentiment'].apply(lambda x: 'Positive' if x > 0 else 'Negative' if x < 0 else 'Neutral')\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "df.to_csv('tweets_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ad8d6",
   "metadata": {},
   "source": [
    "# Time series forecast of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "today = datetime.now().date()\n",
    "\n",
    "# Define the topic and initial date range\n",
    "topic = \"(ios OR apple OR AAPL OR iphone OR ipad)\"\n",
    "start_date = today - timedelta(days=91)\n",
    "\n",
    "# Create a loop to run for 91 days\n",
    "for _ in range(91):\n",
    "    # Calculate the end date for the current iteration\n",
    "    end_date = start_date + timedelta(days=1)\n",
    "    \n",
    "    # Format the dates as strings\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Define the search query with the current date range\n",
    "    query = f\"{topic} until:{end_date_str} since:{start_date_str}\"\n",
    "    \n",
    "    # Fetch tweets on the specified topic\n",
    "    try:\n",
    "        tweets = []\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=query, lang='en', tweet_mode='extended').items(1500):\n",
    "            tweets.append({\n",
    "                'Date': tweet.created_at.date(),\n",
    "                'Tweet': tweet.full_text\n",
    "            })\n",
    "        \n",
    "        if len(tweets) > 0:\n",
    "            print(\"Tweets downloaded successfully for the date range:\", start_date_str, \"to\", end_date_str)\n",
    "            \n",
    "            # Convert the tweets list into a DataFrame\n",
    "            df_new = pd.DataFrame(tweets)\n",
    "            \n",
    "            # Check if the CSV file already exists\n",
    "            if os.path.isfile('tweets.csv'):\n",
    "                # Read the existing data from the CSV file\n",
    "                try:\n",
    "                    df_existing = pd.read_csv('tweets.csv')\n",
    "                except EmptyDataError:\n",
    "                    # Handle the case when the CSV file is empty\n",
    "                    df_existing = pd.DataFrame()\n",
    "                \n",
    "                # Check if the existing DataFrame is empty\n",
    "                if df_existing.empty:\n",
    "                    # Save the new DataFrame to a new CSV file\n",
    "                    df_new.to_csv('tweets.csv', index=False)\n",
    "                    print(\"New CSV file created with the downloaded tweets.\")\n",
    "                else:\n",
    "                    # Concatenate the existing and new data\n",
    "                    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "                    \n",
    "                    # Save the combined DataFrame to the CSV file\n",
    "                    df_combined.to_csv('tweets.csv', index=False)\n",
    "                    print(\"Tweets appended to the existing CSV file.\")\n",
    "            else:\n",
    "                # Save the new DataFrame to a new CSV file\n",
    "                df_new.to_csv('tweets.csv', index=False)\n",
    "                print(\"New CSV file created with the downloaded tweets.\")\n",
    "        else:\n",
    "            print(\"No tweets found for the date range:\", start_date_str, \"to\", end_date_str)\n",
    "            \n",
    "    except tweepy.TweepyException as e:\n",
    "        if e.api_code == 88:\n",
    "            # Rate limit reached, wait for the specified duration\n",
    "            wait_time = int(e.response.headers['Retry-After'])\n",
    "            print(\"Rate limit reached. Sleeping for:\", wait_time, \"seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "        print(\"Error: Failed to download tweets.\")\n",
    "        print(e)\n",
    "    \n",
    "    # Update the start date for the next iteration\n",
    "    start_date = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert forecast data to strings\n",
    "forecast_1w_str = forecast_1w.to_string(header=False)\n",
    "forecast_1m_str = forecast_1m.to_string(header=False)\n",
    "forecast_3m_str = forecast_3m.to_string(header=False)\n",
    "# Print the forecast data\n",
    "print(\"1 Week Forecast:\")\n",
    "print(forecast_1w_str)\n",
    "print(\"1 Month Forecast:\")\n",
    "print(forecast_1m_str)\n",
    "print(\"3 Months Forecast:\")\n",
    "print(forecast_3m_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1901ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
