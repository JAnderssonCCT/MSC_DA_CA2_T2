{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c85e1ba",
   "metadata": {},
   "source": [
    "# Loading the credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65039743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Twitter API credentials from the config file\n",
    "import json\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    consumer_key = config['consumer_key']\n",
    "    consumer_secret = config['consumer_secret']\n",
    "    access_token = config['access_token']\n",
    "    access_token_secret = config['access_token_secret']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d1610",
   "metadata": {},
   "source": [
    "# Disabling warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374410ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c567c",
   "metadata": {},
   "source": [
    "# Downloading twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Authenticate with the Twitter API using Tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Define the search query and parameters\n",
    "query = \"volunteering\"\n",
    "count = 100  # maximum number of tweets per request\n",
    "max_tweets = 10000  # maximum number of tweets to download\n",
    "since_date = \"2022-05-01\"  # earliest date to search from\n",
    "until_date = \"2023-05-01\"  # latest date to search to\n",
    "\n",
    "# Open a CSV file to save the tweets to\n",
    "with open(\"tweets.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row to the CSV file\n",
    "    writer.writerow([\"created_at\", \"text\"])\n",
    "\n",
    "    # Download the tweets using pagination\n",
    "    tweets = []\n",
    "    num_tweets = 0\n",
    "    for page in tweepy.Cursor(api.search_tweets, q=query, count=count, lang=\"en\", since_id=since_date, until=until_date).pages():\n",
    "        for tweet in page:\n",
    "            # Extract the created_at and text fields from the tweet object\n",
    "            created_at = tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            text = tweet.text\n",
    "\n",
    "            # Write the tweet to the CSV file\n",
    "            writer.writerow([created_at, text])\n",
    "\n",
    "            # Increment the tweet count and check if we have reached the maximum number of tweets\n",
    "            num_tweets += 1\n",
    "            if num_tweets >= max_tweets:\n",
    "                break\n",
    "\n",
    "        if num_tweets >= max_tweets:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01153ca5",
   "metadata": {},
   "source": [
    "# Create sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "# Open the CSV file containing the tweets\n",
    "with open(\"tweets.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # skip the header row\n",
    "\n",
    "    # Create a new CSV file to store the sentiment analysis results\n",
    "    with open(\"sentiment.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"created_at\", \"text\", \"polarity\", \"subjectivity\"])\n",
    "\n",
    "        # Iterate over each tweet in the CSV file\n",
    "        for row in reader:\n",
    "            created_at = row[0]\n",
    "            text = row[1]\n",
    "\n",
    "            # Perform sentiment analysis on the tweet text using TextBlob\n",
    "            blob = TextBlob(text)\n",
    "            polarity = blob.sentiment.polarity\n",
    "            subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "            # Write the sentiment analysis results to the new CSV file\n",
    "            writer.writerow([created_at, text, polarity, subjectivity])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e890f0a",
   "metadata": {},
   "source": [
    "# Time series forecast of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Load the sentiment data from the CSV file\n",
    "df = pd.read_csv(\"sentiment.csv\")\n",
    "\n",
    "# Convert the 'created_at' column to a datetime object\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Set the 'created_at' column as the index\n",
    "df.set_index('created_at', inplace=True)\n",
    "\n",
    "# Resample the data by day and calculate the mean sentiment score\n",
    "df_mean = df.resample('D').mean()\n",
    "\n",
    "# Fit an ARIMA model to the mean sentiment data\n",
    "model = sm.tsa.ARIMA(df_mean['polarity'], order=(1, 1, 1)).fit()\n",
    "\n",
    "# Generate predictions for the next 1 week, 1 month and 3 months\n",
    "forecast_1w = model.forecast(steps=7)[0]\n",
    "forecast_1m = model.forecast(steps=30)[0]\n",
    "forecast_3m = model.forecast(steps=90)[0]\n",
    "\n",
    "# Create a Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define a route to display the dashboard\n",
    "@app.route(\"/\")\n",
    "def dashboard():\n",
    "    # Create a Plotly figure with three subplots\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=[\"1 week\", \"1 month\", \"3 months\"])\n",
    "\n",
    "    # Add a line trace for the sentiment forecast in each subplot\n",
    "    fig.add_trace(go.Scatter(x=df_mean.index, y=df_mean['polarity'], mode='lines', name='Sentiment'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.date_range(start=df_mean.index[-1], periods=7, freq='D'), y=forecast_1w, mode='lines', name='Forecast'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.date_range(start=df_mean.index[-1], periods=30, freq='D'), y=forecast_1m, mode='lines', name='Forecast'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=pd.date_range(start=df_mean.index[-1], periods=90, freq='D'), y=forecast_3m, mode='lines', name='Forecast'), row=1, col=3)\n",
    "\n",
    "    # Customize the layout of the figure\n",
    "    fig.update_layout(title=\"Sentiment Forecast Dashboard\", height=500, width=1000)\n",
    "\n",
    "    # Convert the figure to a JSON object\n",
    "    fig_json = fig.to_json()\n",
    "\n",
    "    # Render the dashboard template with the figure JSON data\n",
    "    return render_template(\"dashboard.html\", fig_json=fig_json)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748aae5",
   "metadata": {},
   "source": [
    "# Dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "# Load the tweet data\n",
    "tweet_data = pd.read_csv('tweet_data.csv')\n",
    "\n",
    "# Create a Plotly line chart of the sentiment over time\n",
    "fig = px.line(tweet_data, x='date', y='polarity', title='Sentiment over Time')\n",
    "\n",
    "# Create a Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the app layout\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Sentiment Analysis Dashboard'),\n",
    "    html.Div(children='''A dashboard to display sentiment analysis on a specific topic.'''),\n",
    "    dcc.Graph(id='sentiment-chart', figure=fig)\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
